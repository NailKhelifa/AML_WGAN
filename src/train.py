import torch
import torch.optim as optim
import torch.nn as nn
from torch.autograd import grad
import matplotlib.pyplot as plt
from torch.autograd import Variable

class Trainer:
    def __init__(self, discriminator, generator, dataloader, lr, beta1, beta2, device, mode="normal", lambda_gp=10, gp_weight=10):
        """
        Initialize the Trainer class for GAN or WGAN-GP training.

        Args:
            discriminator: The discriminator model, used to distinguish real data from generated data.
            generator: The generator model, used to produce fake data from latent noise.
            dataloader: DataLoader object providing the training data batches.
            lr: Learning rate for the optimizers.
            beta1: Beta1 hyperparameter for the Adam optimizer.
            beta2: Beta2 hyperparameter for the Adam optimizer.
            device: Device to run the training (e.g., "cuda" for GPU or "cpu").
            mode: "normal" for standard GAN, or "wasserstein" for WGAN-GP.
            lambda_gp: Weight for gradient penalty in WGAN-GP.
            gp_weight: Coefficient for controlling the gradient penalty strength.
        """
        self.discriminator = discriminator
        self.generator = generator
        self.dataloader = dataloader
        self.device = device  # Assign the device (GPU or CPU)
        self.D_loss, self.G_loss, self.gradient_penalty_list, self.D_accuracies = [], [], [], []  # Track metrics during training
        self.lr = lr
        self.gp_weight = gp_weight
        self.beta1 = beta1
        self.beta2 = beta2
        self.mode = mode
        self.lambda_gp = lambda_gp

        # Optimizers for discriminator and generator
        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))
        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))

        # Loss function for standard GANs (only used in "normal" mode)
        if self.mode == "normal":
            self.criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for discriminator

    def sample_latent(self, num_samples):
        """
        Generate latent noise vectors to feed into the generator.

        Args:
            num_samples: Number of latent vectors to generate.

        Returns:
            A tensor of latent noise vectors.
        """
        return torch.randn((num_samples, self.generator.latent_dim))

    def sample_generator(self, num_samples):
        """
        Generate fake data using the generator.

        Args:
            num_samples: Number of samples to generate.

        Returns:
            Generated fake data as a tensor.
        """
        latent_samples = Variable(self.sample_latent(num_samples)).to(self.device)
        generated_data = self.generator(latent_samples)  # Forward pass through the generator
        return generated_data

    def _gradient_penalty(self, real_data, generated_data):
        """
        Compute the gradient penalty for WGAN-GP training.

        Args:
            real_data: Batch of real data samples.
            generated_data: Batch of fake data samples generated by the generator.

        Returns:
            Gradient penalty term for the WGAN-GP loss.
        """
        batch_size = real_data.size(0)

        # Interpolation between real and fake data
        alpha = torch.rand(batch_size, 1, 1, 1, device=self.device)  # Random weights
        interpolated = (alpha * real_data + (1 - alpha) * generated_data).requires_grad_(True)

        # Discriminator's output for interpolated samples
        prob_interpolated = self.discriminator(interpolated)

        # Compute gradients of the discriminator output w.r.t. interpolated samples
        gradients = grad(
            outputs=prob_interpolated,
            inputs=interpolated,
            grad_outputs=torch.ones_like(prob_interpolated),
            create_graph=True,
        )[0]

        # Compute the L2 norm of the gradients
        gradients = gradients.view(batch_size, -1)
        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)

        # Compute gradient penalty
        return self.gp_weight * ((gradients_norm - 1) ** 2).mean()

    def train_discriminator(self, real_data, generated_data):
        """
        Train the discriminator on real and generated data.

        Args:
            real_data: Batch of real data samples.
            generated_data: Batch of fake data samples from the generator.

        Returns:
            Discriminator loss value.
        """
        self.optimizer_D.zero_grad()  # Zero out the gradients from previous step

        if self.mode == "normal":  # Standard GAN training
            # Create labels for real and fake data
            real_labels = torch.ones(real_data.size(0), 1, device=self.device)  # Real -> 1
            fake_labels = torch.zeros(generated_data.size(0), 1, device=self.device)  # Fake -> 0

            # Compute BCE loss for real and fake data
            real_loss = self.criterion(self.discriminator(real_data), real_labels)
            fake_loss = self.criterion(self.discriminator(generated_data.detach()), fake_labels)
            d_loss = real_loss + fake_loss

        elif self.mode == "wasserstein":  # WGAN-GP training
            # Compute gradient penalty
            gp = self._gradient_penalty(real_data, generated_data)
            self.gradient_penalty_list.append(gp.item())  # Track gradient penalty value

            # Wasserstein loss
            d_loss = self.discriminator(generated_data).mean() - self.discriminator(real_data).mean() + gp

        d_loss.backward()  # Backpropagate the loss
        self.optimizer_D.step()  # Update discriminator weights
        return d_loss.item()

    def train_generator(self, generated_data):
        """
        Train the generator to produce realistic fake data.

        Args:
            generated_data: Fake data samples from the generator.

        Returns:
            Generator loss value.
        """
        self.optimizer_G.zero_grad()  # Zero out the gradients

        if self.mode == "normal":  # Standard GAN training
            # Treat generated data as real (label = 1) to fool the discriminator
            real_labels = torch.ones(generated_data.size(0), 1, device=self.device)
            g_loss = self.criterion(self.discriminator(generated_data.detach()), real_labels)

        elif self.mode == "wasserstein":  # WGAN-GP training
            # Minimize the negative mean of discriminator's output (maximize Wasserstein distance)
            g_loss = -self.discriminator(generated_data.detach()).mean()

        # Backpropagate the loss
        g_loss.backward()  # No need for retain_graph=True here
        self.optimizer_G.step()  # Update generator weights
        return g_loss.item()


    def train(self, num_epochs):
        """
        Main training loop for GAN or WGAN-GP.

        Args:
            num_epochs: Number of training epochs.

        Returns:
            Lists of generator loss, discriminator loss, and discriminator accuracy.
        """
        self.discriminator.to(self.device)
        self.generator.to(self.device)

        for epoch in range(num_epochs):
            correct_real, correct_fake, total = 0, 0, 0  # Track discriminator accuracy

            for i, (real_data, _) in enumerate(self.dataloader):
                real_data = real_data.to(self.device)  # Load real data batch to device
                batch_size = real_data.size(0)
                generated_data = self.sample_generator(batch_size)  # Generate fake data

                # Train the discriminator
                d_loss = self.train_discriminator(real_data, generated_data)

                # Train the generator every `n_critic` steps (default: 1 for normal GAN, 5 for WGAN-GP)
                n_critic = 5 if self.mode == "wasserstein" else 1
                if i % n_critic == 0:
                    g_loss = self.train_generator(generated_data)

                # Track losses
                self.G_loss.append(g_loss)
                self.D_loss.append(d_loss)

                # Calculate discriminator accuracy
                real_preds = self.discriminator(real_data)
                fake_preds = self.discriminator(generated_data.detach())
                correct_real += (real_preds > 0.5).sum().item()  # Real -> 1
                correct_fake += (fake_preds < 0.5).sum().item()  # Fake -> 0
                total += batch_size

                # Print progress every 50 iterations
                if i % 50 == 0:
                    accuracy = 100 * (correct_real + correct_fake) / total
                    print(f"[{epoch + 1}/{num_epochs}][{i}/{len(self.dataloader)}]\t"
                          f"Loss_D: {d_loss:.4f}\tLoss_G: {g_loss:.4f}\tAccuracy_D: {accuracy:.2f}%")

            # End of epoch accuracy
            epoch_accuracy = 100 * (correct_real + correct_fake) / total
            self.D_accuracies.append(epoch_accuracy)
            print(f"Epoch [{epoch + 1}/{num_epochs}] - Discriminator Accuracy: {epoch_accuracy:.2f}%")

        return self.G_loss, self.D_loss, self.D_accuracies
